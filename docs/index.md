# MedAISure

Welcome to the MedAISure documentation.

MedAISure is a benchmark for evaluating Large Language Models (LLMs) in the medical domain across realistic tasks such as clinical question answering, diagnostic reasoning, clinical summarization, and patient communication.

## Get started here:

- [Getting Started](getting_started.md)
- [Quick Start](quick_start.md)
- [Usage Guide](usage.md)
- [Architecture Overview](architecture.md)
- [Datasets](datasets/overview.md)

## Key areas:

- [Tasks Overview](tasks/overview.md)
- [Models Guide](models/model_interface.md)
- [Metrics Overview](metrics/overview.md)
- [Datasets](datasets/overview.md)
- [API Reference](api/overview.md)

## Project links:

- [GitHub Repository](https://github.com/junaidi-ai/MedAISure)
- [Issue Tracker](https://github.com/junaidi-ai/MedAISure/issues)

## Quick Links

- [Submission Schema](submission_schema.md)
- [Download JSON Schema](schema/submission.schema.json)
- [How to Submit](leaderboard/how_to_submit.md)

## What's New

- Leaderboard Submission Exporter
  - Export a submission JSON directly during evaluation with `--export-submission`
  - Generate a submission from a saved report using `generate-submission`
  - Strict validation backed by JSON Schema
  - Docs: [Submission Schema](submission_schema.md) Â· [How to Submit](leaderboard/how_to_submit.md)
