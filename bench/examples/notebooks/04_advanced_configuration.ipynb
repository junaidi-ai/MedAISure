{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e79dec",
   "metadata": {},
   "source": [
    "# 04 — Advanced Configuration\n",
    "\n",
    "This notebook demonstrates advanced options when running evaluations:\n",
    "\n",
    "- Custom batch sizes and caching\n",
    "- Exporting additional report formats (JSON, CSV, Markdown, HTML)\n",
    "- Passing generation/inference kwargs (HuggingFace)\n",
    "- Device/dtype and other loading options (HuggingFace)\n",
    "\n",
    "It runs by default with the repo's local demo model and includes a commented example for HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8868f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bench.evaluation.harness import EvaluationHarness\n",
    "from bench.evaluation.result_aggregator import ResultAggregator\n",
    "from pathlib import Path\n",
    "\n",
    "tasks = [\"simple_qa\", \"medical_qa_symptoms\"]\n",
    "h = EvaluationHarness(\n",
    "    tasks_dir=\"bench/tasks\", results_dir=\"results\", cache_dir=\"cache\", log_level=\"INFO\"\n",
    ")\n",
    "\n",
    "# Use a smaller batch size and enable caching\n",
    "rep = h.evaluate(\n",
    "    model_id=\"demo-local-adv\",\n",
    "    task_ids=tasks,\n",
    "    model_type=\"local\",\n",
    "    batch_size=4,\n",
    "    use_cache=True,\n",
    "    save_results=True,\n",
    "    report_formats=[\"json\", \"csv\", \"md\", \"html\"],\n",
    "    module_path=\"bench.examples.mypkg.mylocal\",\n",
    "    model_path=None,\n",
    ")\n",
    "rep.metadata, rep.overall_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447d5ed",
   "metadata": {},
   "source": [
    "Exporting via `ResultAggregator` can also be done manually if you keep results in memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = ResultAggregator(output_dir=\"results\")\n",
    "run_id = rep.metadata.get(\"run_id\")\n",
    "for er in rep.detailed_results:\n",
    "    ra.add_evaluation_result(er, run_id=run_id)\n",
    "\n",
    "ra.export_report_csv(run_id, f\"results/{run_id}.csv\")\n",
    "ra.export_report_markdown(run_id, f\"results/{run_id}.md\")\n",
    "ra.export_report_html(run_id, f\"results/{run_id}.html\", include_examples=True)\n",
    "sorted(Path(\"results\").glob(run_id + \"*\"))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f44c6",
   "metadata": {},
   "source": [
    "## HuggingFace example (optional)\n",
    "\n",
    "To use a HuggingFace pipeline instead of the local demo model, uncomment the cell below.\n",
    "\n",
    "Notes:\n",
    "- You need `transformers` and `torch` installed.\n",
    "- Replace the model and task as desired. For summarization, input fields like `document`/`text`/`note` are supported by the runner.\n",
    "- Advanced options like `device_map`, `torch_dtype`, `low_cpu_mem_usage`, `trust_remote_code`, `revision` are passed through.\n",
    "- Generation kwargs (e.g., `max_new_tokens`) are forwarded for generative tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2098d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bench.evaluation.harness import EvaluationHarness\n",
    "# h_hf = EvaluationHarness(tasks_dir='bench/tasks', results_dir='results', cache_dir='cache')\n",
    "# rep_hf = h_hf.evaluate(\n",
    "#     model_id='hf-tiny-sum',\n",
    "#     task_ids=['clinical_summarization_basic'],\n",
    "#     model_type='huggingface',\n",
    "#     hf_task='summarization',\n",
    "#     model_path='sshleifer/tiny-t5',\n",
    "#     batch_size=2,\n",
    "#     use_cache=True,\n",
    "#     generation_kwargs={'max_new_tokens': 32, 'do_sample': False},\n",
    "#     device=-1,  # CPU; set to 0 for first CUDA GPU if available\n",
    "#     trust_remote_code=False,\n",
    "#     low_cpu_mem_usage=True,\n",
    "# )\n",
    "# rep_hf.overall_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56616e85",
   "metadata": {},
   "source": [
    "## Performance tips\n",
    "\n",
    "See the comprehensive guide: [Performance Tips — MedAISure] (docs/04c_performance_tips.md).\n",
    "\n",
    "Highlights:\n",
    "- Use smaller batch sizes on constrained hardware.\n",
    "- Enable caching (`use_cache=True`) to avoid recomputation.\n",
    "- For HuggingFace, set appropriate `device` and `torch_dtype` (e.g., 'float16'/'bfloat16').\n",
    "- Limit `max_new_tokens` and sample size when iterating.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
